{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f68364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Starting Week 6: Data Retrieval and Processing\n",
      "🔗 Connecting to blockchain...\n",
      "✅ Connected to Ganache successfully!\n",
      "✅ Connected to Smart Contract\n",
      "\n",
      "📁 Looking for logistics data file...\n",
      "📋 CSV files found in current directory: ['cleaned_iot_data.csv', 'Logistics-Data.csv', 'W6-Cleaned_Iot_Data.csv']\n",
      "✅ Found and loaded: Logistics-Data.csv\n",
      "📊 Data shape: (100, 10)\n",
      "📋 Columns: ['timestamp', 'package_id', 'origin', 'destination', 'location', 'closest_city', 'status', 'temperature', 'humidity', 'shock']\n",
      "📄 Using data file: Logistics-Data.csv\n",
      "📋 First few rows:\n",
      "                    timestamp package_id     origin destination  \\\n",
      "0  2025-04-29 12:08:30.336512   PKG85046  São Paulo      Moscow   \n",
      "1  2025-04-29 13:17:30.336512   PKG59811      Tokyo       Seoul   \n",
      "2  2025-04-29 14:36:30.336512   PKG80313  Cape Town       Seoul   \n",
      "3  2025-04-29 15:23:30.336512   PKG90642      Tokyo   São Paulo   \n",
      "4  2025-04-29 16:06:30.336512   PKG86797     Moscow      Berlin   \n",
      "\n",
      "            location closest_city      status  temperature  humidity  shock  \n",
      "0   33.3012, 13.5857        Cairo  In Transit         26.0      51.6   0.20  \n",
      "1  36.7251, 136.1661        Tokyo  In Transit         11.7      84.9   0.20  \n",
      "2   24.1418, 107.766      Bangkok  In Transit         34.1      83.4   0.04  \n",
      "3    3.6758, 36.9013        Cairo  In Transit         21.8      49.2   0.48  \n",
      "4   52.3556, 18.2952       Berlin  In Transit         13.9      81.2   0.37  \n",
      "✅ All required columns found!\n",
      "\n",
      "📊 Analyzing data requirements...\n",
      "📦 Total packages in CSV: 100\n",
      "📊 Total CSV records: 100\n",
      "🎯 Expected blockchain records: 300 (3 sensors × 100 packages)\n",
      "📈 Current blockchain records: 30\n",
      "\n",
      "⚠️ Incomplete data on blockchain! Have 30, need 300\n",
      "\n",
      "📤 Storing ALL IoT data to blockchain...\n",
      "🚀 This will store 300 records total...\n",
      "🔑 Authorizing device...\n",
      "✅ Device authorized successfully!\n",
      "📦 Processing ALL 100 packages...\n",
      "📊 Progress: 1/100 packages processed...\n",
      "   🛰️ Stored [PKG85046] - temperature: 26.0\n",
      "   🛰️ Stored [PKG85046] - humidity: 51.6\n",
      "   🛰️ Stored [PKG85046] - shock: 0.2\n",
      "   🛰️ Stored [PKG59811] - temperature: 11.7\n",
      "   🛰️ Stored [PKG59811] - humidity: 84.9\n",
      "   🛰️ Stored [PKG59811] - shock: 0.2\n",
      "   🛰️ Stored [PKG80313] - temperature: 34.1\n",
      "   🛰️ Stored [PKG80313] - humidity: 83.4\n",
      "   🛰️ Stored [PKG80313] - shock: 0.04\n",
      "📊 Progress: 11/100 packages processed...\n",
      "📊 Progress: 21/100 packages processed...\n",
      "📊 Progress: 31/100 packages processed...\n",
      "📊 Progress: 41/100 packages processed...\n",
      "📊 Progress: 51/100 packages processed...\n",
      "📊 Progress: 61/100 packages processed...\n",
      "📊 Progress: 71/100 packages processed...\n",
      "📊 Progress: 81/100 packages processed...\n",
      "📊 Progress: 91/100 packages processed...\n",
      "\n",
      "✅ Data storage completed!\n",
      "📊 Successfully stored: 300 records\n",
      "❌ Failed to store: 0 records\n",
      "🎯 Success rate: 100.0%\n",
      "📈 Final blockchain record count: 330\n",
      "\n",
      "📥 Retrieving ALL IoT records from blockchain...\n",
      "📊 Found 330 total records to retrieve...\n",
      "📥 Retrieved 50/330 records...\n",
      "📥 Retrieved 100/330 records...\n",
      "📥 Retrieved 150/330 records...\n",
      "📥 Retrieved 200/330 records...\n",
      "📥 Retrieved 250/330 records...\n",
      "📥 Retrieved 300/330 records...\n",
      "✅ Successfully retrieved 330 records from blockchain!\n",
      "\n",
      "🔧 Processing 330 records for analysis...\n",
      "\n",
      "📋 COMPLETE Data Processing Summary:\n",
      "   📦 Total records processed: 330\n",
      "   📱 Unique packages: 100\n",
      "   📈 Sensor types: temperature, humidity, shock\n",
      "   🌍 Cities covered: 19\n",
      "   📅 Date range: 2025-04-29 12:08:30.336512 to 2025-05-06 10:09:30.336512\n",
      "\n",
      "📊 Complete Sensor Data Analysis:\n",
      "   temperature: 110 readings\n",
      "     Range: 0.60 - 42.50\n",
      "     Average: 19.32 ± 9.86\n",
      "   humidity: 110 readings\n",
      "     Range: 41.70 - 96.00\n",
      "     Average: 74.36 ± 11.76\n",
      "   shock: 110 readings\n",
      "     Range: 0.01 - 1.98\n",
      "     Average: 0.30 ± 0.30\n",
      "\n",
      "💾 Saving complete cleaned dataset...\n",
      "✅ Complete cleaned IoT data saved successfully as cleaned_iot_data.csv\n",
      "📊 File contains 330 records from 100 packages\n",
      "\n",
      "📈 Data ready for line chart visualization:\n",
      "   ✅ Total records: 330\n",
      "   ✅ Unique packages: 100\n",
      "   ✅ Records per sensor type:\n",
      "     temperature: 110 records\n",
      "     humidity: 110 records\n",
      "     shock: 110 records\n",
      "\n",
      "🎉 SUCCESS! Complete dataset with 330 records ready for Week 7 visualization!\n",
      "📁 Output file: cleaned_iot_data.csv\n",
      "🎯 This represents ALL your IoT data from blockchain storage!\n"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Step 1: Retrieve your Milestone 1 output to start the retrieval process\n",
    "print(\"📥 Starting Week 6: Data Retrieval and Processing\")\n",
    "print(\"🔗 Connecting to blockchain...\")\n",
    "\n",
    "# Connect to Ganache blockchain\n",
    "ganache_url = \"http://127.0.0.1:7545\"\n",
    "web3 = Web3(Web3.HTTPProvider(ganache_url))\n",
    "\n",
    "if web3.is_connected():\n",
    "    print(\"✅ Connected to Ganache successfully!\")\n",
    "else:\n",
    "    print(\"❌ Connection failed. Make sure Ganache is running.\")\n",
    "    exit()\n",
    "\n",
    "# Contract details (from your Week 5 deployment)\n",
    "contract_address = web3.to_checksum_address(\"0x2df65fed5311cc0349b4967d5fefd91e39a8866e\")\n",
    "contract_abi = [\n",
    "    # Your contract ABI (same as Week 5)\n",
    "    {\n",
    "        \"inputs\": [{\"internalType\": \"address\",\"name\": \"device\",\"type\": \"address\"}],\n",
    "        \"name\": \"authorizeDevice\",\"outputs\": [],\"stateMutability\": \"nonpayable\",\"type\": \"function\"\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": [{\"internalType\": \"address\",\"name\": \"device\",\"type\": \"address\"}],\n",
    "        \"name\": \"revokeDevice\",\"outputs\": [],\"stateMutability\": \"nonpayable\",\"type\": \"function\"\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            {\"internalType\": \"string\",\"name\": \"deviceID\",\"type\": \"string\"},\n",
    "            {\"internalType\": \"string\",\"name\": \"dataType\",\"type\": \"string\"},\n",
    "            {\"internalType\": \"string\",\"name\": \"value\",\"type\": \"string\"}\n",
    "        ],\n",
    "        \"name\": \"storeData\",\"outputs\": [],\"stateMutability\": \"nonpayable\",\"type\": \"function\"\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": [],\"stateMutability\": \"nonpayable\",\"type\": \"constructor\"\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": [{\"internalType\": \"address\",\"name\": \"\",\"type\": \"address\"}],\n",
    "        \"name\": \"authorizedDevices\",\"outputs\": [{\"internalType\": \"bool\",\"name\": \"\",\"type\": \"bool\"}],\n",
    "        \"stateMutability\": \"view\",\"type\": \"function\"\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            {\"internalType\": \"string\",\"name\": \"deviceID\",\"type\": \"string\"},\n",
    "            {\"internalType\": \"uint256\",\"name\": \"index\",\"type\": \"uint256\"}\n",
    "        ],\n",
    "        \"name\": \"getDataByIndex\",\n",
    "        \"outputs\": [\n",
    "            {\"internalType\": \"string\",\"name\": \"\",\"type\": \"string\"},\n",
    "            {\"internalType\": \"string\",\"name\": \"\",\"type\": \"string\"},\n",
    "            {\"internalType\": \"uint256\",\"name\": \"\",\"type\": \"uint256\"}\n",
    "        ],\n",
    "        \"stateMutability\": \"view\",\"type\": \"function\"\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": [{\"internalType\": \"string\",\"name\": \"deviceID\",\"type\": \"string\"}],\n",
    "        \"name\": \"getDataCount\",\n",
    "        \"outputs\": [{\"internalType\": \"uint256\",\"name\": \"\",\"type\": \"uint256\"}],\n",
    "        \"stateMutability\": \"view\",\"type\": \"function\"\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": [],\"name\": \"owner\",\n",
    "        \"outputs\": [{\"internalType\": \"address\",\"name\": \"\",\"type\": \"address\"}],\n",
    "        \"stateMutability\": \"view\",\"type\": \"function\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load the smart contract\n",
    "contract = web3.eth.contract(address=contract_address, abi=contract_abi)\n",
    "web3.eth.default_account = web3.eth.accounts[0]\n",
    "print(\"✅ Connected to Smart Contract\")\n",
    "\n",
    "# Step 1.5: Find and load CSV file\n",
    "print(\"\\n📁 Looking for logistics data file...\")\n",
    "\n",
    "# List of possible CSV file names\n",
    "possible_files = [\n",
    "    \"LogisticsData.csv\",\n",
    "    \"Logistics-Data.csv\", \n",
    "    \"logistics_data.csv\",\n",
    "    \"logistics-data.csv\",\n",
    "    \"IoT_Data.csv\",\n",
    "    \"iot_data.csv\"\n",
    "]\n",
    "\n",
    "df_original = None\n",
    "csv_filename = None\n",
    "\n",
    "# Check current directory for CSV files\n",
    "current_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "print(f\"📋 CSV files found in current directory: {current_files}\")\n",
    "\n",
    "# Try to find the logistics data file\n",
    "for filename in possible_files:\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            df_original = pd.read_csv(filename)\n",
    "            csv_filename = filename\n",
    "            print(f\"✅ Found and loaded: {filename}\")\n",
    "            print(f\"📊 Data shape: {df_original.shape}\")\n",
    "            print(f\"📋 Columns: {list(df_original.columns)}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {filename}: {e}\")\n",
    "\n",
    "# If still no file found, try the first CSV file in directory\n",
    "if df_original is None and current_files:\n",
    "    try:\n",
    "        csv_filename = current_files[0]\n",
    "        df_original = pd.read_csv(csv_filename)\n",
    "        print(f\"✅ Using first available CSV: {csv_filename}\")\n",
    "        print(f\"📊 Data shape: {df_original.shape}\")\n",
    "        print(f\"📋 Columns: {list(df_original.columns)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading {csv_filename}: {e}\")\n",
    "\n",
    "if df_original is None:\n",
    "    print(\"❌ No logistics data file found. Please ensure you have LogisticsData.csv in your directory.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"📄 Using data file: {csv_filename}\")\n",
    "print(\"📋 First few rows:\")\n",
    "print(df_original.head())\n",
    "\n",
    "# Verify required columns exist\n",
    "required_columns = ['package_id', 'timestamp', 'temperature', 'humidity', 'shock']\n",
    "missing_columns = [col for col in required_columns if col not in df_original.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"❌ Missing required columns: {missing_columns}\")\n",
    "    print(\"📋 Available columns:\", list(df_original.columns))\n",
    "    exit()\n",
    "\n",
    "print(\"✅ All required columns found!\")\n",
    "\n",
    "# Step 2: Check blockchain data and determine what to store\n",
    "print(\"\\n📊 Analyzing data requirements...\")\n",
    "\n",
    "device_ids = df_original[\"package_id\"].unique()\n",
    "total_csv_records = len(df_original)\n",
    "expected_blockchain_records = total_csv_records * 3  # 3 sensors per package\n",
    "\n",
    "print(f\"📦 Total packages in CSV: {len(device_ids)}\")\n",
    "print(f\"📊 Total CSV records: {total_csv_records}\")\n",
    "print(f\"🎯 Expected blockchain records: {expected_blockchain_records} (3 sensors × {total_csv_records} packages)\")\n",
    "\n",
    "# Check current blockchain state\n",
    "total_records = 0\n",
    "for device_id in device_ids:\n",
    "    try:\n",
    "        device_count = contract.functions.getDataCount(str(device_id)).call()\n",
    "        total_records += device_count\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error checking records for {device_id}: {e}\")\n",
    "\n",
    "print(f\"📈 Current blockchain records: {total_records}\")\n",
    "\n",
    "# Decide whether to store data\n",
    "if total_records == 0:\n",
    "    print(f\"\\n⚠️ No data on blockchain! Need to store ALL {expected_blockchain_records} records...\")\n",
    "    store_data = True\n",
    "elif total_records < expected_blockchain_records:\n",
    "    print(f\"\\n⚠️ Incomplete data on blockchain! Have {total_records}, need {expected_blockchain_records}\")\n",
    "    store_data = True\n",
    "else:\n",
    "    print(f\"\\n✅ Complete data already on blockchain! ({total_records} records)\")\n",
    "    store_data = False\n",
    "\n",
    "# Store ALL data if needed\n",
    "if store_data:\n",
    "    print(f\"\\n📤 Storing ALL IoT data to blockchain...\")\n",
    "    print(f\"🚀 This will store {expected_blockchain_records} records total...\")\n",
    "    \n",
    "    # Authorize the current account\n",
    "    try:\n",
    "        print(\"🔑 Authorizing device...\")\n",
    "        auth_txn = contract.functions.authorizeDevice(web3.eth.default_account).transact({\n",
    "            'from': web3.eth.default_account,\n",
    "            'gas': 3000000\n",
    "        })\n",
    "        web3.eth.wait_for_transaction_receipt(auth_txn)\n",
    "        print(\"✅ Device authorized successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Authorization issue (may already exist): {e}\")\n",
    "    \n",
    "    # Store ALL data from CSV to blockchain\n",
    "    stored_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"📦 Processing ALL {len(df_original)} packages...\")\n",
    "    \n",
    "    for index, row in df_original.iterrows():\n",
    "        device_id = str(row[\"package_id\"])\n",
    "        \n",
    "        # Store temperature, humidity, and shock data\n",
    "        sensors = [\n",
    "            (\"temperature\", str(row[\"temperature\"])),\n",
    "            (\"humidity\", str(row[\"humidity\"])), \n",
    "            (\"shock\", str(row[\"shock\"]))\n",
    "        ]\n",
    "        \n",
    "        # Show progress every 10 packages\n",
    "        if index % 10 == 0:\n",
    "            print(f\"📊 Progress: {index+1}/{len(df_original)} packages processed...\")\n",
    "        \n",
    "        for sensor_type, sensor_value in sensors:\n",
    "            try:\n",
    "                txn = contract.functions.storeData(device_id, sensor_type, sensor_value).transact({\n",
    "                    'from': web3.eth.default_account,\n",
    "                    'gas': 3000000\n",
    "                })\n",
    "                web3.eth.wait_for_transaction_receipt(txn)\n",
    "                stored_count += 1\n",
    "                \n",
    "                # Show detailed progress for first few records\n",
    "                if index < 3:\n",
    "                    print(f\"   🛰️ Stored [{device_id}] - {sensor_type}: {sensor_value}\")\n",
    "                \n",
    "                # Small delay to prevent overwhelming Ganache\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                failed_count += 1\n",
    "                print(f\"   ❌ Failed to store {sensor_type} for {device_id}: {e}\")\n",
    "    \n",
    "    print(f\"\\n✅ Data storage completed!\")\n",
    "    print(f\"📊 Successfully stored: {stored_count} records\")\n",
    "    print(f\"❌ Failed to store: {failed_count} records\")\n",
    "    print(f\"🎯 Success rate: {(stored_count/(stored_count+failed_count)*100):.1f}%\")\n",
    "    \n",
    "    # Verify final count\n",
    "    final_count = 0\n",
    "    for device_id in device_ids:\n",
    "        try:\n",
    "            device_count = contract.functions.getDataCount(str(device_id)).call()\n",
    "            final_count += device_count\n",
    "        except:\n",
    "            pass\n",
    "    print(f\"📈 Final blockchain record count: {final_count}\")\n",
    "\n",
    "# Step 3: Retrieve ALL data from blockchain\n",
    "print(f\"\\n📥 Retrieving ALL IoT records from blockchain...\")\n",
    "\n",
    "# Get current total\n",
    "total_records = 0\n",
    "for device_id in device_ids:\n",
    "    try:\n",
    "        device_count = contract.functions.getDataCount(str(device_id)).call()\n",
    "        total_records += device_count\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if total_records == 0:\n",
    "    print(\"❌ No data on blockchain to retrieve!\")\n",
    "    exit()\n",
    "\n",
    "print(f\"📊 Found {total_records} total records to retrieve...\")\n",
    "\n",
    "# Retrieve ALL records\n",
    "data = []\n",
    "retrieved_count = 0\n",
    "\n",
    "for device_id in device_ids:\n",
    "    try:\n",
    "        device_count = contract.functions.getDataCount(str(device_id)).call()\n",
    "        \n",
    "        if device_count > 0:\n",
    "            # Get original data for this device\n",
    "            device_original_data = df_original[df_original[\"package_id\"] == device_id].iloc[0]\n",
    "            \n",
    "            # Get each record for this device from blockchain\n",
    "            for i in range(device_count):\n",
    "                try:\n",
    "                    # Get record from blockchain\n",
    "                    blockchain_record = contract.functions.getDataByIndex(str(device_id), i).call()\n",
    "                    \n",
    "                    # Structure data following original instructions format\n",
    "                    data.append({\n",
    "                        \"timestamp\": device_original_data[\"timestamp\"],\n",
    "                        \"device_id\": device_id,\n",
    "                        \"data_type\": blockchain_record[0],\n",
    "                        \"data_value\": blockchain_record[1],\n",
    "                        \"location\": device_original_data.get(\"location\", \"Unknown\"),\n",
    "                        \"closest_city\": device_original_data.get(\"closest_city\", \"Unknown\"),\n",
    "                        \"status\": device_original_data.get(\"status\", \"Unknown\"),\n",
    "                        \"origin\": device_original_data.get(\"origin\", \"Unknown\"),\n",
    "                        \"destination\": device_original_data.get(\"destination\", \"Unknown\")\n",
    "                    })\n",
    "                    retrieved_count += 1\n",
    "                    \n",
    "                    # Show progress\n",
    "                    if retrieved_count % 50 == 0:\n",
    "                        print(f\"📥 Retrieved {retrieved_count}/{total_records} records...\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error retrieving record {i} for {device_id}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing device {device_id}: {e}\")\n",
    "\n",
    "print(f\"✅ Successfully retrieved {len(data)} records from blockchain!\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 4: Data preprocessing and cleaning\n",
    "print(f\"\\n🔧 Processing {len(df)} records for analysis...\")\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "# Extract numeric values\n",
    "df[\"numeric_value\"] = df[\"data_value\"].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
    "\n",
    "# Handle missing values\n",
    "missing_count = df[\"numeric_value\"].isnull().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"⚠️ Found {missing_count} missing values, filling with 0\")\n",
    "    df[\"numeric_value\"].fillna(0, inplace=True)\n",
    "\n",
    "# Fill other missing values\n",
    "df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Step 5: Data quality summary\n",
    "print(f\"\\n📋 COMPLETE Data Processing Summary:\")\n",
    "print(f\"   📦 Total records processed: {len(df)}\")\n",
    "print(f\"   📱 Unique packages: {df['device_id'].nunique()}\")\n",
    "print(f\"   📈 Sensor types: {', '.join(df['data_type'].unique())}\")\n",
    "print(f\"   🌍 Cities covered: {df['closest_city'].nunique()}\")\n",
    "print(f\"   📅 Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "\n",
    "# Show complete sensor data ranges\n",
    "print(f\"\\n📊 Complete Sensor Data Analysis:\")\n",
    "for data_type in df['data_type'].unique():\n",
    "    type_data = df[df['data_type'] == data_type]['numeric_value']\n",
    "    if len(type_data) > 0:\n",
    "        print(f\"   {data_type}: {len(type_data)} readings\")\n",
    "        print(f\"     Range: {type_data.min():.2f} - {type_data.max():.2f}\")\n",
    "        print(f\"     Average: {type_data.mean():.2f} ± {type_data.std():.2f}\")\n",
    "\n",
    "# Step 6: Save the complete cleaned dataset\n",
    "print(f\"\\n💾 Saving complete cleaned dataset...\")\n",
    "\n",
    "try:\n",
    "    df.to_csv(\"cleaned_iot_data.csv\", index=False)\n",
    "    print(\"✅ Complete cleaned IoT data saved successfully as cleaned_iot_data.csv\")\n",
    "    print(f\"📊 File contains {len(df)} records from {df['device_id'].nunique()} packages\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving CSV: {e}\")\n",
    "\n",
    "# Step 7: Final verification\n",
    "print(f\"\\n📈 Data ready for line chart visualization:\")\n",
    "print(f\"   ✅ Total records: {len(df)}\")\n",
    "print(f\"   ✅ Unique packages: {df['device_id'].nunique()}\")\n",
    "print(f\"   ✅ Records per sensor type:\")\n",
    "for sensor in df['data_type'].unique():\n",
    "    count = len(df[df['data_type'] == sensor])\n",
    "    print(f\"     {sensor}: {count} records\")\n",
    "\n",
    "print(f\"\\n🎉 SUCCESS! Complete dataset with {len(df)} records ready for Week 7 visualization!\")\n",
    "print(f\"📁 Output file: cleaned_iot_data.csv\")\n",
    "print(f\"🎯 This represents ALL your IoT data from blockchain storage!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
